{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcce756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ¬´yolov5¬ª‚Ä¶\n",
      "remote: Enumerating objects: 12447, done.\u001b[K\n",
      "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
      "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
      "remote: Total 12447 (delta 30), reused 37 (delta 11), pack-reused 12381\u001b[K\n",
      "–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤: 100% (12447/12447), 12.21 –ú–∏–ë | 2.96 –ú–∏–ë/—Å, –≥–æ—Ç–æ–≤–æ.\n",
      "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π: 100% (8574/8574), –≥–æ—Ç–æ–≤–æ.\n",
      "/home/sirius/Tracking/yolov5\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32091/2552324790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install -q roboflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_output\u001b[0m  \u001b[0;31m# to display images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#clone YOLOv5 and \n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt # install dependencies\n",
    "%pip install -q roboflow\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c748ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.0-cp39-cp39-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 776.3 MB 41 kB/s eta 0:00:0129\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/sirius/anaconda3/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bee6b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.11.0+cu102 (NVIDIA GeForce RTX 2080)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69730c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4188620616.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_12169/4188620616.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    wandb login()\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wandb login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1ff09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying training data\n",
      "copying validation data\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, random\n",
    "\n",
    "# preparing the folder structure\n",
    "\n",
    "full_data_path = 'data/obj/'\n",
    "extension_allowed = '.jpg'\n",
    "split_percentage = 85\n",
    "\n",
    "images_path = 'data/images/'\n",
    "if os.path.exists(images_path):\n",
    "    shutil.rmtree(images_path)\n",
    "os.mkdir(images_path)\n",
    "    \n",
    "labels_path = 'data/labels/'\n",
    "if os.path.exists(labels_path):\n",
    "    shutil.rmtree(labels_path)\n",
    "os.mkdir(labels_path)\n",
    "    \n",
    "training_images_path = images_path + 'training/'\n",
    "validation_images_path = images_path + 'validation/'\n",
    "training_labels_path = labels_path + 'training/'\n",
    "validation_labels_path = labels_path +'validation/'\n",
    "    \n",
    "os.mkdir(training_images_path)\n",
    "os.mkdir(validation_images_path)\n",
    "os.mkdir(training_labels_path)\n",
    "os.mkdir(validation_labels_path)\n",
    "\n",
    "files = []\n",
    "\n",
    "ext_len = len(extension_allowed)\n",
    "\n",
    "for r, d, f in os.walk(full_data_path):\n",
    "    for file in f:\n",
    "        if file.endswith(extension_allowed):\n",
    "            strip = file[0:len(file) - ext_len]      \n",
    "            files.append(strip)\n",
    "\n",
    "random.shuffle(files)\n",
    "\n",
    "size = len(files)                   \n",
    "\n",
    "split = int(split_percentage * size / 100)\n",
    "\n",
    "print(\"copying training data\")\n",
    "for i in range(split):\n",
    "    strip = files[i]\n",
    "                         \n",
    "    image_file = strip + extension_allowed\n",
    "    src_image = full_data_path + image_file\n",
    "    shutil.copy(src_image, training_images_path) \n",
    "                         \n",
    "    annotation_file = strip + '.txt'\n",
    "    src_label = full_data_path + annotation_file\n",
    "    shutil.copy(src_label, training_labels_path) \n",
    "\n",
    "print(\"copying validation data\")\n",
    "for i in range(split, size):\n",
    "    strip = files[i]\n",
    "                         \n",
    "    image_file = strip + extension_allowed\n",
    "    src_image = full_data_path + image_file\n",
    "    shutil.copy(src_image, validation_images_path) \n",
    "                         \n",
    "    annotation_file = strip + '.txt'\n",
    "    src_label = full_data_path + annotation_file\n",
    "    shutil.copy(src_label, validation_labels_path) \n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc3d5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbr0fire\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights & Biases  (optional)\n",
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd09a6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sirius/Files/task\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13324ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d715ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09303edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677605b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbr0fire\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=dataset.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 7 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤: 100% (7/7), 13.55 –ö–∏–ë | 2.26 –ú–∏–ë/—Å, –≥–æ—Ç–æ–≤–æ.\n",
      "–ò–∑ https://github.com/ultralytics/yolov5\n",
      "   526e650..7dafd1c  master      -> origin/master\n",
      " * [–Ω–æ–≤–∞—è –≤–µ—Ç–∫–∞]     fix/iou_nan -> origin/fix/iou_nan\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.1-289-g526e650 Python-3.9.7 torch-1.11.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080, 7979MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/sirius/Tracking/wandb/run-20220711_164949-1glansrg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33methereal-thunder-26\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/br0fire/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/br0fire/train/runs/1glansrg\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7022326 parameters, 7022326 gradients\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 2080) 7.79G total, 0.08G reserved, 0.05G allocated, 7.66G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     7022326           0         0.292         10.06         20.73        (1, 3, 640, 640)                    list\n",
      "     7022326           0         0.510         9.732         22.84        (2, 3, 640, 640)                    list\n",
      "     7022326           0         1.046          12.3         38.86        (4, 3, 640, 640)                    list\n",
      "     7022326           0         1.923         23.56         75.17        (8, 3, 640, 640)                    list\n",
      "     7022326           0         3.704         43.65         139.8       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 29 for CUDA:0 6.67G/7.79G (86%) ‚úÖ\n",
      "Scaled weight_decay = 0.000453125\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/sirius/Tracking/yolov5/../data/labels/training' images an\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/sirius/Tracking/yolov5/../data/labels/training.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/sirius/Tracking/yolov5/../data/labels/validation' images an\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/sirius/Tracking/yolov5/../data/labels/validation.cache\n",
      "Plotting labels to yolov5/runs/train/exp7/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.55 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/exp7\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/99     5.77G    0.1153   0.02739         0         8       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        108        159     0.0013      0.264    0.00205   0.000449\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/99     5.45G   0.09046   0.02505         0        14       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        108        159      0.224       0.27      0.109     0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/99     5.45G   0.07874   0.02274         0        14       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        108        159      0.389       0.42       0.35      0.121\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/99     5.45G    0.0678     0.021         0         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        108        159      0.341      0.346      0.238     0.0824\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/99     5.45G   0.06283   0.02106         0        18       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        108        159      0.432      0.547      0.417      0.132\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/99     5.45G   0.05454   0.01757         0        77       640:  82%|‚ñà‚ñà‚ñà"
     ]
    }
   ],
   "source": [
    "!python3 yolov5/train.py --img 640 --batch -1 --epochs 100 --data dataset.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6806afec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5/runs/train/exp6/weights/best.pt'], source=data/testroid, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=badges, name=test228, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 üöÄ v6.1-289-g526e650 Python-3.9.7 torch-1.11.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080, 7979MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "image 1/18 /home/sirius/Tracking/data/testroid/asd.jpg: 640x480 1 badge, Done. (0.014s)\n",
      "image 2/18 /home/sirius/Tracking/data/testroid/azaz.jpg: 640x480 1 badge, Done. (0.012s)\n",
      "image 3/18 /home/sirius/Tracking/data/testroid/batar.jpg: 480x640 Done. (0.013s)\n",
      "image 4/18 /home/sirius/Tracking/data/testroid/ggg.jpg: 640x480 Done. (0.013s)\n",
      "image 5/18 /home/sirius/Tracking/data/testroid/lol.jpg: 640x480 Done. (0.012s)\n",
      "image 6/18 /home/sirius/Tracking/data/testroid/phome.jpg: 480x640 Done. (0.012s)\n",
      "image 7/18 /home/sirius/Tracking/data/testroid/q.jpg: 640x480 Done. (0.012s)\n",
      "image 8/18 /home/sirius/Tracking/data/testroid/ss.jpg: 640x480 2 badges, Done. (0.012s)\n",
      "image 9/18 /home/sirius/Tracking/data/testroid/t1.jpg: 640x480 1 badge, Done. (0.012s)\n",
      "image 10/18 /home/sirius/Tracking/data/testroid/t2.jpg: 640x480 1 badge, Done. (0.012s)\n",
      "image 11/18 /home/sirius/Tracking/data/testroid/t3.jpg: 640x480 Done. (0.012s)\n",
      "image 12/18 /home/sirius/Tracking/data/testroid/t4.jpg: 640x480 2 badges, Done. (0.012s)\n",
      "image 13/18 /home/sirius/Tracking/data/testroid/t5.jpg: 640x480 2 badges, Done. (0.013s)\n",
      "image 14/18 /home/sirius/Tracking/data/testroid/t6.jpg: 640x480 3 badges, Done. (0.012s)\n",
      "image 15/18 /home/sirius/Tracking/data/testroid/ur1.jpg: 640x480 Done. (0.012s)\n",
      "image 16/18 /home/sirius/Tracking/data/testroid/ur2.jpg: 640x480 Done. (0.012s)\n",
      "image 17/18 /home/sirius/Tracking/data/testroid/wer.jpg: 640x480 1 badge, Done. (0.013s)\n",
      "image 18/18 /home/sirius/Tracking/data/testroid/wood.jpg: 480x640 Done. (0.013s)\n",
      "Speed: 0.3ms pre-process, 12.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mbadges/test22817\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 yolov5/detect.py --source 'data/testroid' --weights 'yolov5/runs/train/exp6/weights/best.pt' --conf 0.6 --iou 0.45 --augment --project 'badges' --name 'test228'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0c75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
